---
title: "PCA and ISOMAP Dimension Reduction"
author: "Andomei Smit: SMTAND051"
date: "02/03/2025"
output:
  pdf_document:
    toc: true
    toc_depth: 2
    fig_caption: true
    keep_tex: yes
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos = 'H')
```

# Load packages

```{r packages, warning=FALSE, message=FALSE}
library(dplyr)
library(tidyr)
library(xtable)
library(splitstackshape)
library(FactoMineR)
library(ggplot2)
library(factoextra)
library(lattice)
library(permute)
library(vegan)
Sys.setenv(RGL_USE_NULL = TRUE) # need this to get RDRToolbox installed
library(RDRToolbox)
library(FNN)
library(e1071)
library(patchwork)
library(parallel)
rm(list=ls())
```

# Load data

```{r load_data}
ard1 <- read.csv("created_data/ard1.csv") # full cleaned data set (analysis ready data 1)

# drop the first column:
ard1 <- ard1[,-1]
```


# Dimension Reduction

## PCA

```{r}
# columns to ignore:
ignore_cols <- c("Species", "ID", "sample_num")
data.pca <- princomp(ard1[,-which(colnames(ard1)%in% ignore_cols)])
summary(data.pca)

fviz_eig(data.pca, addlabels = FALSE, barcolor = "darkgreen", barfill = "darkgreen", ncp = 15)


# cumulative variance: 
## 4pcs: 0.48 - possible first elbow
## 10pcs: 0.65 - possible second elbow
## 30pcs: 0.84 - large proportion of variance
```
```{r pca_plot}
# save this plot to pdf
pdf("plots/pca_scree_plot.pdf", width = 4, height = 2.5)  # You can adjust width/height if needed

fviz_eig(data.pca, addlabels = FALSE, barcolor = "darkgreen", barfill = "darkgreen", ncp = 15, ylab = "Percentage of \n variance explained")

dev.off()
```


```{r pca_csv}
pca.scores <- data.pca$scores # all scores
# write the transformed data from 4PCs to csv
write.csv(pca.scores[,1:4], "created_data/pca_4pcs_data.csv")

# write the transformed data from 10PCs to csv
write.csv(pca.scores[,1:10], "created_data/pca_10pcs_data.csv")

# write the transformed data from 30PCs to csv
write.csv(pca.scores[,1:30], "created_data/pca_30pcs_data.csv")
```

## ISOMAP
First find the smallest k such that the graph of nearest neighbours is fully connected.

### Find smallest viable value of k
```{r isomap_min_k}
# columns to ignore:
ignore_cols <- c("Species", "ID", "sample_num")
data_cols <- which(colnames(ard1)%in% ignore_cols)

# Find the smallest k that allows ISOMAP to run
k_values <- seq(5, 30, 1)  # Test k from 5 to 30
optimal_k <- NA

for (k in k_values) {
  tryCatch({
    isomap_result <- isomap(dist(as.matrix(ard1[,-data_cols])), ndim = 2, k = k)
    optimal_k <- k  # If ISOMAP runs successfully, store k and break loop
    break
  }, error = function(e) {
    # If an error occurs, continue to next k
  })
}

# Print the first valid k
if (!is.na(optimal_k)) {
  print(paste("Optimal k (smallest fully connected graph):", optimal_k))
} else {
  print("None of the current values for k resulted in a fully connected graph. Increase k and retry.")
}
```

Smallest k is 16. Thus we can test a range of k from 16 to 30.

### Find optimal value of k and d using residual variance
In order to do this, we will fix the number of dimensions to use for MDS iteratively between 2 to 20 and iterate through possible values of K. For each value of k for a set dimension for the MDS, the residual variance will be calculated and stored. The aim is to find a value of k and corresponding dimensions for MDS that will minimize this variance.

In order to calculate the residual variance, we need the original geodesic distances, that is the sum of the euclidean distances along the shortest paths from the K-nn graphs.

```{r function_geodesic_distance}
# function to calculate the geodesic distances in the original high dimensional space
calc_geodestic_dist <- function(k, ard1, data_cols) {
  n <- nrow(ard1)
  # get k-nn for given k
  knearestn <- get.knn(ard1[,-data_cols], k = k)
  neighbor_index <- as.matrix(knearestn$nn.index) # index of neighbors
  neighbor_dist <- as.matrix(knearestn$nn.dist) # distance to neighbors

  nn_distances <- matrix(NA, nrow = n, ncol = n)
  for(i in 1:n) {
    for(j in 1:k) {
      # store distance to from i to jth neighbor
      nn_distances[i, neighbor_index[i, j]] <- neighbor_dist[i, j]
    }
  }
  # get shortest paths along neihborhood graph
  shortest_paths <- allShortestPaths(nn_distances)
  geodesicdist <- matrix(0, n, n)
  
  # calculate geodesic distance as the sum of path 
  # along neighborhood graph
  for (i in 1:n) {
    for(j in 1:n) {
      path <- extractPath(shortest_paths, i, j)
      total_dist <- sum(nn_distances[path[-length(path)], path[-1]])
      geodesicdist[i,j] <- total_dist
    }
  }
  # set diagnoal to zero (i to i)
  diag(geodesicdist) <- 0
  return(geodesicdist)
}

```

Next we need a function to calculate the residual variances.

```{r function_residual_variances}
# function to calculate the residual variances
calc_residual_variance <- function(geodesic_distances, isomap_embedding) {
  # distance between points in the lower dimension
  reduced_distances <- as.matrix(dist(isomap_embedding))
  
  # Flatten both matrices into vectors for correlation calculation
  geo_vector <- as.vector(geodesic_distances)
  euclid_vector <- as.vector(reduced_distances)
  
  # calculate person correlation between two distance vectors
  R2 <- cor(geo_vector, euclid_vector, use = "complete.obs")^2
  residual_variance <- 1 - R2 
  return(residual_variance)
}

```


Lastly, we need a function that puts all of this together.

```{r function_isomap_tuning}
isomap_tuning <- function(k_nn, d, ard1, data_cols) {
  # get the isomap configuration for the given k and d
  isomap_result <- isomap(dist(as.matrix(ard1[,-data_cols])), 
                          ndim = d, k = k_nn)
  # calculate the geodesic distance
  geodesic_dist <- calc_geodestic_dist(k_nn, ard1, data_cols)
  # calculate the residual variance
  resid_var <- calc_residual_variance(geodesic_dist, isomap_result$points)
  return(resid_var)
}

```

NOTE that this code will still take several minutes to compute, even with parallel computing.

```{r parallel_computing}
# parameter grid
k_values <- seq(16, 51, 5)   # values of k to test
d_values <- seq(2, 72, 10)   # values of d to test
param_grid <- expand.grid(k_nn = k_values, d = d_values)

# apply in parallel
residual_variances <- mcmapply(
  FUN = isomap_tuning,
  k_nn = param_grid$k_nn,
  d = param_grid$d,
  MoreArgs = list(ard1 = ard1, data_cols = data_cols),
  mc.cores = detectCores() - 1
)

# store and save
results_df <- cbind(param_grid, residual_variance = residual_variances)
write.csv(results_df, "created_data/isomap_tuning_results.csv", row.names = FALSE)
```


```{r isomap_plots}
# Plot residual variance vs. k (lines for d)
plot_k_vs_residual <- ggplot(results_df, aes(x = k_nn, y = residual_variance, color = as.factor(d))) +
  geom_line(linewidth = 0.4) +
  geom_point(size = 1.5) +
  labs(title = "Residual Variance vs. k",
       x = "Number of Neighbors (k)",
       y = "Residual Variance",
       color = "Dimensions (d)") +
  theme_minimal() +
  theme(legend.position = "right",
    axis.title.x = element_text(margin =  margin(t = 10)), 
    axis.title.y = element_text(margin = margin(r = 10))   )

# Plot residual variance vs. d (lines for k)
plot_d_vs_residual <- ggplot(results_df, aes(x = d, y = residual_variance, color = as.factor(k_nn))) +
  geom_line(linewidth = 0.4) +
  geom_point(size = 1.5) +
  labs(title = "Residual Variance vs. d",
       x = "Number of Dimensions (d)",
       y = "Residual Variance",
       color = "Neighbors (k)") +
  theme_minimal() +
  theme(legend.position = "right",,
    axis.title.x = element_text(margin =  margin(t = 10)), 
    axis.title.y = element_text(margin = margin(r = 10))) +
  geom_vline(xintercept = 22, linetype = "dashed", color = "black", linewidth = 0.6) +
  annotate("text", x = 30, y = 0.50, label = "d = 22", color = "black", vjust = -1)

# Show both plots
print(plot_k_vs_residual)
print(plot_d_vs_residual)

# Save the first plot (Residual Variance vs. k, different d values)
ggsave("plots/residual_vs_k.pdf", plot = plot_k_vs_residual, width = 6, height = 4)

# Save the second plot (Residual Variance vs. d, different k values)
ggsave("plots/residual_vs_d.pdf", plot = plot_d_vs_residual, width = 6, height = 4)
```

```{r isomap_combined_plot}
combined_plot <- plot_d_vs_residual + plot_k_vs_residual

combined_plot <- combined_plot + plot_annotation(
  title = "Residual Variance vs. k and d",
  theme = theme(plot.title = element_text(size = 16, hjust = 0.5))
)

ggsave("plots/residual_variance_combined.pdf", plot = combined_plot, width = 9, height = 3.5)
```

From the plot that separates the lines based on dimensions, we see that the number of dimensions does not differentiate a reduction in residual variance past 22. I.e. from dimensions 22 onwards, there is not much gain in reduction of residual variance for higher dimensions as compared to d = 22. Setting the number of dimensions to 22 and trying to find a suitable value for k, it can be seen that there is only a slight reduction in variance for k equal to 16, 21 and 26. These are 0.38, 0.33 and 0.28, respectively. However, the final decision will be left after the clustering algorithm has been applied.

```{r isomap_resid_var_calc}
# residual variance for k = 21 and d = 22
results_df$residual_variance[which(results_df$k_nn== 21 & results_df$d==22)] # 0.33

# residual variance for k = 26 and d = 22
results_df$residual_variance[which(results_df$k_nn== 26 & results_df$d==22)] # 0.28

# residual variance for k = 16 and d = 22
results_df$residual_variance[which(results_df$k_nn== 16 & results_df$d==22)] # 0.38
```

```{r isomap_csv}
# isomap with k = 16 and d = 22
isomap_k16_d22 <- isomap(dist(as.matrix(ard1[,-data_cols])), ndim = 22, k = 16)
write.csv(isomap_k16_d22$points, "created_data/isomap_k16_d22.csv")

# isomap with k = 21 and d = 22
isomap_k21_d22 <- isomap(dist(as.matrix(ard1[,-data_cols])), ndim = 22, k = 21)
write.csv(isomap_k21_d22$points, "created_data/isomap_k21_d22.csv")

# isomap with k = 26 and d = 22
isomap_k26_d22 <- isomap(dist(as.matrix(ard1[,-data_cols])), ndim = 22, k = 26)
write.csv(isomap_k26_d22$points, "created_data/isomap_k26_d22.csv")
```
